{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.005,\n",
    "    'last_drop': 0.2,\n",
    "    'max_epochs': 20,\n",
    "    'patience': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning import Trainer\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from torchvision.models import mobilenet_v2\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "num_classes = len([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "num_workers = int(os.cpu_count() / 2)\n",
    "\n",
    "val_split = 0.2\n",
    "\n",
    "test_split = 0.1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data.iloc[idx]['image_path']\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        return image, label\n",
    "\n",
    "class ImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, batch_size=32, num_workers=1, transform=None, val_split=0.2, test_split=0.2, random_state=42):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transform\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        data = self.load_data()\n",
    "        train_data, test_val_data = train_test_split(data, test_size=self.val_split + self.test_split, random_state=self.random_state, stratify=data['label'])\n",
    "        val_data, test_data = train_test_split(test_val_data, test_size=self.test_split / (self.val_split + self.test_split), random_state=self.random_state, stratify=test_val_data['label'])\n",
    "\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = ImageDataset(train_data, transform=self.transform)\n",
    "            self.val_dataset = ImageDataset(val_data, transform=self.transform)\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_dataset = ImageDataset(test_data, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def load_data(self):\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "        class_dirs = [d for d in os.listdir(self.data_dir) if os.path.isdir(os.path.join(self.data_dir, d))]\n",
    "        class_names = sorted(class_dirs)\n",
    "\n",
    "        for idx, class_name in enumerate(class_names):\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            for img_path in os.listdir(class_dir):\n",
    "                if img_path == '.DS_Store':  # Skip .DS_Store files\n",
    "                    continue\n",
    "                image_path = os.path.join(class_dir, img_path)\n",
    "                image_paths.append(image_path)\n",
    "                labels.append(idx)\n",
    "\n",
    "        data = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model  Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2Lightning(pl.LightningModule):\n",
    "    def __init__(self, num_classes, pretrained=True, lr=0.001, last_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = lr\n",
    "        self.model = mobilenet_v2(pretrained=pretrained)\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=last_drop, inplace=False),\n",
    "            nn.Linear(self.model.last_channel, num_classes)\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.90)\n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = hparams['batch_size']\n",
    "lr = hparams['lr']\n",
    "last_drop = hparams['last_drop']\n",
    "max_epochs = hparams['max_epochs']\n",
    "patience = hparams['patience']\n",
    "\n",
    "dataModule = ImageDataModule(data_dir=data_dir, batch_size=batch_size, num_workers=num_workers, transform=transform, val_split=val_split, test_split=test_split, random_state=random_state)\n",
    "model = MobileNetV2Lightning(num_classes=num_classes, lr=lr, last_drop=last_drop)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "trainer = Trainer(devices='auto', \n",
    "                    accelerator='auto', \n",
    "                    max_epochs=max_epochs,\n",
    "                    logger=True, \n",
    "                    enable_checkpointing=True,\n",
    "                    callbacks=[lr_monitor, early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate Training/Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=dataModule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
